print("Accuracy for Raw Data")
Accuracy(class_table$`raw`, class_table$class)
library(forecast)
Accuracy(class_table$`raw`, class_table$class)
accuracy(class_table$`raw`, class_table$class)
library(data.table)
library(genlasso)
library(rpart)
library(rattle)
library(ggplot2)
library(mltools)
library(caret)
library(forecast)
set.seed(100)
cbf_train <- data.table(read.table("~/Documents/GitHub/fall21-ferhatturhan/files/CBF_TRAIN.txt", quote="\"", comment.char=""))
setnames(cbf_train,'V1','class')
cbf_train <- cbf_train[order(class)]
cbf_train[,class:=as.character(class)]
cbf_train[,id:=1:.N]
long_cbf=melt(cbf_train,id.vars=c('id','class'))
long_cbf[,time:=as.numeric(gsub("\\D", "", variable))-1]
long_cbf=long_cbf[,list(id,class,time,value)]
long_cbf=long_cbf[order(id,time)]
head(long_cbf)
out_trial <- trendfilter(as.numeric(cbf_train[1,2:129]), ord = 0)
cv_trial <- cv.trendfilter(out_trial) # k=10 by default
plot(out_trial, lambda=cv_trial$lambda.min, main="Minimal CV error")
plot(out_trial, lambda=cv_trial$lambda.1se, main="One standard error rule")
for (i in 1:30)
{
out <- trendfilter(as.numeric(cbf_train[i,2:129]), ord = 0)
cv <- cv.trendfilter(out, k = 10)
long_cbf[(128*(i-1)+1):(128*i),"1D Fused Lasso" := out$fit[,match(cv$lambda.1se, out$lambda)]]
}
head(long_cbf)
par(mfrow = c(1,3))
ggplot(long_cbf[id == 14], aes( x = time, y = value, color = "Original Values")) +
geom_point() +
geom_line(aes( x = long_cbf$time[1665:1792], y = long_cbf$`1D Fused Lasso`[1665:1792], color = "Representation with 1D Fused Lasso")) +
labs(title = "Example ID: 14")
ggplot(long_cbf[id == 26], aes( x = time, y = value, color = "Original Values")) +
geom_point() +
geom_line(aes( x = long_cbf$time[3201:3328], y = long_cbf$`1D Fused Lasso`[3201:3328], color = "Representation with 1D Fused Lasso")) +
labs(title = "Example ID: 26")
ggplot(long_cbf[id == 7], aes( x = time, y = value, color = "Original Values")) +
geom_point() +
geom_line(aes( x = long_cbf$time[769:896], y = long_cbf$`1D Fused Lasso`[769:896], color = "Representation with 1D Fused Lasso")) +
labs(title = "Example ID: 7")
errors_trial <- vector()
for(i in 1:30)
{
base_tree_trial <- rpart(value~time, long_cbf[id == 1], control =
rpart.control(minsplit = 20, minbucket = 10, cp = 0, maxdepth = i))
errors_trial[i] <- base_tree_trial$cptable[which.min(base_tree_trial$cptable[, "CP"]), "xerror"]
}
best_error_tree_trial <- rpart(value~time, long_cbf[id == 1], control =
rpart.control(minsplit = 20, minbucket = 10, cp = 0, maxdepth = which.min(errors_trial)))
print("Best maxdepth parameter for the first time series is:")
print(which.min(errors_trial))
fancyRpartPlot(best_error_tree_trial,sub = "")
long_cbf[(1:128), "Regression Trees" := predict(best_error_tree_trial, long_cbf[id == 1])]
ggplot(long_cbf[id == 1], aes( x = time, y = value, color = "Original Values")) +
geom_point() +
geom_line(aes( x = long_cbf$time[1:128], y = long_cbf$`Regression Trees`[1:128], color = "Representation with Regression Tree"))
errors <- vector()
for(j in 1:30)
{
for(i in 1:30)
{
base_tree <- rpart(value~time, long_cbf[id == j], control =
rpart.control(minsplit = 20, minbucket = 10, cp = 0, maxdepth = i))
errors[i] <- base_tree$cptable[which.min(base_tree$cptable[, "CP"]), "xerror"]
}
best_error_tree <- rpart(value~time, long_cbf[id == j], control =
rpart.control(minsplit = 20, minbucket = 10, cp = 0, maxdepth = which.min(errors)))
long_cbf[(128*(j-1)+1):(128*j), "Regression Trees" := predict(best_error_tree, long_cbf[id == j])]
}
head(long_cbf)
par(mfrow = c(1,3))
ggplot(long_cbf[id == 14], aes( x = time, y = value, color = "Original Values")) +
geom_point() +
geom_line(aes( x = long_cbf$time[1665:1792], y = long_cbf$`Regression Trees`[1665:1792], color = "Representation with Regression Tree")) +
labs(title = "Example ID: 14")
ggplot(long_cbf[id == 26], aes( x = time, y = value, color = "Original Values")) +
geom_point() +
geom_line(aes( x = long_cbf$time[3201:3328], y = long_cbf$`Regression Trees`[3201:3328], color = "Representation with Regression Tree")) +
labs(title = "Example ID: 26")
ggplot(long_cbf[id == 7], aes( x = time, y = value, color = "Original Values")) +
geom_point() +
geom_line(aes( x = long_cbf$time[769:896], y = long_cbf$`Regression Trees`[769:896], color = "Representation with Regression Tree")) +
labs(title = "Example ID: 7")
mse_table <- as.data.table(c(1:30))
setnames(mse_table,'V1','id')
for(i in 1:30)
{
mse_table[i, '1D Fused Lasso' := mse(long_cbf[id == i]$value, long_cbf[id == i]$`1D Fused Lasso`)]
mse_table[i, 'Regression Trees' := mse(long_cbf[id == i]$value, long_cbf[id == i]$'Regression Trees')]
}
head(mse_table)
boxplot(mse_table$`1D Fused Lasso`, main = "1D Fused Lasso", ylim = c(0, 0.3))
boxplot(mse_table$`Regression Trees`, main = "Regression Tree", ylim = c(0, 0.3))
raw <- matrix(NA, nrow = 30, ncol = 30)
part1 <- matrix(NA, nrow = 30, ncol = 30)
part2 <- matrix(NA, nrow = 30, ncol = 30)
class_table <- cbf_train[,1]
class_table[,raw:= NA]
class_table[,'1D Fused Lasso' := NA]
class_table[,'Regression Trees' := NA]
raw_v <- vector()
part1_v <- vector()
part2_v <- vector()
euclidean <- function(a, b) sqrt(sum((a - b)^2))
for (i in 1:30)
{
for (j in 1:30)
{
if (i == j)
next()
else
{
raw[i,j] = euclidean(long_cbf[id == i]$value, long_cbf[id == j]$value)
part1[i,j] = euclidean(long_cbf[id == i]$value, long_cbf[id == j]$`1D Fused Lasso`)
part2[i,j] = euclidean(long_cbf[id == i]$value, long_cbf[id == j]$`Regression Trees`)
}
}
raw_v[i] = cbf_train[which.min(raw[i,]),class]
part1_v[i] = cbf_train[which.min(part1[i,]),class]
part2_v[i] = cbf_train[which.min(part2[i,]),class]
}
class_table[,'raw'] <- raw_v
class_table[,'1D Fused Lasso'] <- part1_v
class_table[,'Regression Trees'] <- part2_v
class_table
print("Accuracy for Raw Data")
accuracy(class_table$`raw`, class_table$class)
accuracy(ts(class_table$`1D Fused Lasso`), class_table$class)
accuracy(ts(class_table$`1D Fused Lasso`), ts(class_table$class))
table(class_table$`raw`, class_table$class)
print("Confusion Matrix for Raw Data")
table(class_table$`raw`, class_table$class)
print("Confusion Matrix for 1D Fused Lasso ")
table(class_table$`1D Fused Lasso`, class_table$class)
print("Confusion Matrix for Regression Trees")
table(class_table$`Regression Trees`, class_table$class)
table(class_table$`Regression Trees`, class_table$class) %>%
prop.table() %>% round(digits = 3)
table(class_table$`1D Fused Lasso`, class_table$class)
table(class_table$`Regression Trees`, class_table$class)
